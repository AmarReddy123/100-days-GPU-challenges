{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%%writefile LOAD_SIZE.cu\n",
        "#define LOAD_SIZE 32\n",
        "#include <iostream>\n",
        "#include <cuda_runtime.h>\n",
        "// going to code Brent-Kung algorithm\n",
        "__global__ void prefixsum_kernel(float* A,float* C,int N){\n",
        "  int threadId=threadIdx.x;\n",
        "  int i=2*blockDim.x*blockIdx.x+threadId;\n",
        "\n",
        "  //load in shared memory\n",
        "\n",
        "  __shared__ float S_A[LOAD_SIZE];\n",
        "  if (i<N){\n",
        "    S_A[threadId]=A[i];\n",
        "  }\n",
        "  if (i+blockDim.x<N){\n",
        "    S_A[threadId+blockDim.x]=A[i+blockDim.x];\n",
        "  }\n",
        "  __syncthreads();\n",
        "\n",
        "for(int jump=1;jump<=blockDim.x;jump*=2){\n",
        "  //I need to sync the threads because I need all their values for the next iteration\n",
        "  __syncthreads();\n",
        "  int j= jump*2*(threadId+1) -1;\n",
        "  if (j<LOAD_SIZE){\n",
        "    //I think this will make the threads in the warp inactive, but just a first approximation I'm going to do it like this.\n",
        "\n",
        "    S_A[j]+=S_A[j-jump];\n",
        "  }}\n",
        "  __syncthreads();\n",
        "\n",
        "//Now the reduction part\n",
        "//just by pattern recognition the tree is flipped so I assume we just flip the previous algorithm somehow.\n",
        "\n",
        "\n",
        "for(int jump=LOAD_SIZE/4;jump>=1;jump/=2){\n",
        "  //I need to sync the threads because I need all their values for the next iteration\n",
        "  __syncthreads();\n",
        "  int j= jump*2*(threadId+1) -1;\n",
        "  if (j<LOAD_SIZE-jump){\n",
        "\n",
        "     S_A[j+jump]+=S_A[j];\n",
        "  }\n",
        "  __syncthreads();\n",
        "}\n",
        "if (i<N) C[i]=S_A[threadId];\n",
        "if (i<N-blockDim.x) C[i+blockDim.x]=S_A[threadId+blockDim.x];\n",
        "__syncthreads();\n",
        "\n",
        "\n",
        "}\n",
        "\n",
        "\n",
        "void checkCudaError(const char *message) {\n",
        "    cudaError_t error = cudaGetLastError();\n",
        "    if (error != cudaSuccess) {\n",
        "        printf(\"CUDA error (%s): %s\\n\", message, cudaGetErrorString(error));\n",
        "        exit(-1);\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "int main(){\n",
        "  int N=10;\n",
        "  float A[N],C[N];\n",
        "for (int i = 0; i < N; i++) {\n",
        "    A[i] = i + 1.0f;\n",
        "}\n",
        "  float* d_A;\n",
        "  float* d_C;\n",
        "  cudaMalloc(&d_A,N*sizeof(float));\n",
        "  cudaMalloc(&d_C,N*sizeof(float));\n",
        "  cudaMemcpy(d_A,A,N*sizeof(float),cudaMemcpyHostToDevice);\n",
        "  checkCudaError(\"Failed to copy input data to device\");\n",
        "  dim3 dimBlock(32);\n",
        "  dim3 dimGrid((N + dimBlock.x - 1) / dimBlock.x);\n",
        "  prefixsum_kernel<<<dimGrid, dimBlock>>>(d_A,d_C,N);\n",
        "  checkCudaError(\"Failed to execute the kernel\");\n",
        "  cudaDeviceSynchronize();\n",
        "  cudaMemcpy(C,d_C,N*sizeof(float),cudaMemcpyDeviceToHost);\n",
        "checkCudaError(\"Failed to copy output data to host\");\n",
        "\n",
        "cudaFree(d_A);\n",
        "cudaFree(d_C);\n",
        "\n",
        "\n",
        "//printing the results\n",
        "printf(\"A:\\n\");\n",
        "for (int i=0; i<N;i++){\n",
        "  printf(\"%.2f \", A[i]);\n",
        "\n",
        "}\n",
        "printf(\"C:\\n\");\n",
        "for (int i=0; i<N;i++){\n",
        "  printf(\"%.2f \", C[i]);\n",
        "\n",
        "}\n",
        "}"
      ],
      "metadata": {
        "id": "RZtcjK5TYuO7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49794e58-34cc-4a17-e9c0-3aefeeec69b6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting LOAD_SIZE.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile with the specified architecture\n",
        "!nvcc LOAD_SIZE.cu -o LOAD_SIZE -gencode arch=compute_75,code=sm_75\n",
        "\n",
        "# Run the executable\n",
        "!./LOAD_SIZE"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XK-tjlNT1hs0",
        "outputId": "4bfcd5ee-2c2a-4834-ba20-b398cc983bc6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A:\n",
            "1.00 2.00 3.00 4.00 5.00 6.00 7.00 8.00 9.00 10.00 C:\n",
            "1.00 3.00 6.00 10.00 15.00 21.00 28.00 36.00 45.00 55.00 "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-qHrBSeZ1u2M"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}